# Smart\_Calendar



# Участники проекта

Баженов Савелий, Симонов Константин, Третьяк Антон

# Определение проблемы



В компаниях постоянно есть общие события и дедлайны, которые нельзя пропустить, поэтому нужно вести календарь этих событий, однако в таком случае только один пользователь может редактировать его и просматривать, а с остальными ему не удобно делится. Это приводит к тому что компания не может быстро ввести информацию в календарь если этого администратора нет на месте. Компания не может быстро отреагировать на изменения и уведомить своих сотрудников, что может создать огромные проблемы.



# Выработка требований - пользовательские сценарии

- Создать свой личный календарь<br>
- Дать право доступа и роль другому человеку<br>
- Возможность создавать и редактировать повторяющиеся события

#### 1\. *Регистрация нового пользователя*
&nbsp;	Я - новый пользователь, я хочу зарегистрироваться с уникальным логином и паролем, чтобы получить доступ к своему личному календарю.

#### 2\. *Вход в систему*
&nbsp;	Когда я уже зарегистрированный пользователь, я хочу войти в систему с помощью своего логина и пароля, чтобы войти в свой календарь.

#### 3\. *Добавление участников в календарь*
&nbsp;	Когда у меня уже есть свой календарь, я хочу добавить участников по их email и указать их роль в календаре.

#### 4\. *Добавление ролей участников*
&nbsp;	Владелец должен мочь добавлять модераторов на читателей, а модератор должен мочь добавлять только читателей.

#### 5\. *Изменение ролей участников*
&nbsp;	Владелец должен уметь изменять роли пользователей с модераторов на читателей и наоборот.

#### 6\. *Безопасный выход пользователя*
&nbsp;	Когда человек заканчивает работу в календаре, он хочет безопасно выйти из системы, чтобы защитить свою учетную запись.



# Архитектура проекта



## *Нагрузка на сервис*

#### 1) Соотношение R/W нагрузки 80/20
&nbsp;	Основная нагрузка на чтение - это проверка событий, роли участников и их количество<br>
&nbsp;	Основная нагрузка на запись - это запись событий в календарь

#### 2) Объемы трафика

&nbsp; Загрузка календаря<br>
&nbsp; 10 000 пользователей и 20 загрузок в день = 200 000 запросов/день<br>
&nbsp; Возьмем в среднем 5 изменений событий в день на пользователя = 50 000 запросов/день<br>
&nbsp; Служебные запросы тоже возьмем 50 000 запросов/день<br>
&nbsp; **Итого 300 000 запросов/день**<br><br>
&nbsp; Загрузка календаря 200 000 \* 0.3 КБ<br>
&nbsp; Создание/обновление событий 50 000 \* 1 КБ<br>
&nbsp; Служебные запросы 50 000 \* 0.3 КБ<br>
&nbsp; **Запросы: 125 МБ / день**<br><br>
&nbsp; Ответы же вышли больше<br>
&nbsp; 1.27 ГБ / день<br>
&nbsp; **ИТОГО: 1.4 ГБ / день**<br>

#### Объемы дисковой системы
При расчёте на 10 000 пользователей и средней пользовательской активности (2 календаря на пользователя, 20 событий на календарь, из них 30% повторяющихся) объём данных составляет порядка 12 ГБ в год. Основной вклад в рост дисковой системы вносит таблица materialized occurrences, содержащая конкретные появления повторяющихся событий.<br><br>	
**Оценки памяти для хранения одного объекта**
- Пользователь — 0.3 КБ
- Календарь — 0.4 КБ
- Событие (event) — 0.8 КБ
- Задача (task) — 0.7 КБ
- Occurrence (материализованное повторение) — 0.5 КБ
- Служебная запись (outbox\_job) — 0.5 КБ

Вводные данные: 10 000 пользователей всего<br>
В среднем:
- 2 календаря на пользователя
- 20 событий на календарь
- 30% событий — повторяющиеся
- Средняя частота повторения:
  - 1 occurrence в 2 дня

Предположим рост 20 новых пользователей в день (6 КБ / день):
- Календари (16 КБ / день)
- События (640 КБ / день)
- Повторяющиеся события → occurrences (60 КБ / день)
- Задачи (560 КБ / день)
- Служебные данные (200 КБ / день)

**ИТОГО: 1.5 МБ / день или 550 МБ / год. За 5 лет 2750 МБ**

## *Container Diagram (Уровень 1)*
![model1](/Pictures/model1.png)


## *Container Diagram (Уровень 2)*
![model2](/Pictures/model2.png)


## *Контракты API*
- Получение списка календарей пользователя: ``GET /api/v1/calendars``
- Получение событий календаря за период: ``GET /api/v1/calendars/{calendar\_id}/events``
- Создание события: ``POST /api/v1/calendars/{calendar\_id}/events``
- Обновление события: ``PUT /api/v1/events/{event\_id}``
- Удаление события: ``DELETE /api/v1/events/{event\_id}``
- Получение задач пользователя: ``GET /api/v1/tasks``

## *Нефункциональные требования*
- Чтение календаря ≤ 200 мс
- Получение списка событий ≤ 300 мс
- Создание / обновление события ≤ 400 мс
- Удаление события ≤ 300 мс

#### *Пропускная способность*
- Средняя нагрузка: ~1 000 RPS
- Пиковая нагрузка: до 3 000 RPS
- Система должна обрабатывать пиковую нагрузку без деградации SLA.

#### *Надёжность и отказоустойчивость*
- Сервис должен быть доступен 99.9% времени
- Отказ Redis не должен приводить к недоступности сервиса
- Все критические данные хранятся в PostgreSQL

#### *Масштабируемость*
- Горизонтальное масштабирование API Server
- Stateless API → масштабируется за load balancer
- Возможность вынесения background worker в отдельный контейнер

#### *Консистентность данных*
- PostgreSQL используется как single source of truth
- ACID-гарантии для операций записи
- Асинхронные операции (occurrences) не блокируют HTTP-запросы

#### *Безопасность*
- Аутентификация пользователя на уровне API
- Проверка прав доступа к календарям
- Валидация входных данных
- Защита от перегрузки (rate limiting)



## *Схема БД*

![BD](/Pictures/BD.png)


## *Почему схема выдерживает нефункциональные требования*
 *Время отклика* (чтение календаря) ≤ 300 мс


#### *Пропускная способность*
Основная нагрузка — чтение. Чтения работают по одной таблице и одному диапазонному индексу
PostgreSQL эффективно обслуживает тысячи RPS на таких запросах, особенно при hot-data cache в RAM.

#### *Масштабируемость*

API stateless → масштабируется горизонтально
PostgreSQL:
- read-replicas для масштабирования чтения
- партиционирование occurrences по start\_ts при росте
	
#### *Изоляция тяжёлых операций*
###### Materialization повторений вынесена в outbox\_jobs
- HTTP-запросы не блокируются и не зависят от фоновых операций

###### Управляемый рост данных
- occurrences растёт линейно
- Возможно ограничение горизонта (например, +6 месяцев) или очистка старых occurrences, архивирование


# Схема масштабирования сервиса при росте нагрузки в 10 раз

## Горизонтальное масштабирование

#### Calendar API Server
- Запуск нескольких инстансов Calendar API Server за load balancer (nginx / HAProxy / cloud LB)
- Stateless-архитектура сервиса позволяет масштабировать API горизонтально без синхронизации состояния между инстансами
- Каждый инстанс обслуживает ограниченное количество RPS, нагрузка равномерно распределяется балансировщиком
- Использование keep-alive соединений и асинхронной обработки запросов для снижения latency

#### Background Workers (outbox)
- Выделение отдельного пула background worker’ов
- Масштабирование количества воркеров независимо от API Server
- Асинхронная обработка:
 - materialization повторяющихся событий;
 - пересчёт occurrences при изменениях;
 - очистка устаревших данных.

#### PostgreSQL
Настройка репликации:
- 1 primary (master) — операции записи
- 2–4 read replicas — операции чтения
- Read-запросы (~80% нагрузки) направляются на read replicas
- Write-запросы (~20% нагрузки) выполняются на primary
- Партиционирование таблицы occurrences по времени (месяц / квартал) для эффективной работы с большими объёмами данных
- Использование connection pooling (PgBouncer) для оптимального использования соединений

#### Redis
Использование Redis для:
- кэширования календарей за период;
- хранения часто запрашиваемых данных;
- снижения нагрузки на PostgreSQL при read-heavy нагрузке.
<br>
При росте нагрузки:
- переход на Redis Cluster для горизонтального масштабирования;
- использование Redis Sentinel для обеспечения высокой доступности и failover.

## Вертикальное масштабирование
- Увеличение ресурсов (CPU, RAM) контейнеров Calendar API Server для обработки большего количества одновременных запросов
- Увеличение ресурсов PostgreSQL:
- Больше RAM для page cache и индексов;
- Больше CPU для выполнения параллельных запросов

Вертикальное масштабирование используется как дополнительная мера до достижения пределов горизонтального масштабирования

#### Оптимизация
Кэширование:
- Кэширование часто запрашиваемых данных (календари за период, список событий) в Redis
- Снижение количества обращений к БД на 50–70%

#### Асинхронная обработка
- Тяжёлые операции (materialization повторений, пересчёт occurrences) выполняются асинхронно через outbox-паттерн
- HTTP-запросы остаются быстрыми и не блокируются


# UNIT тестирование
Тесты запускаются с помощью этой команды: ``ctest --output-on-failure``

# Интеграционное тестирование
Запускается той же командой что и UNIT тестирование

#### Сборка
Настройки сервера:
```
export JWT\_SECRET=supersecretkey
export DB\_HOST=127.0.0.1
export DB\_PORT=5432
export DB\_NAME=calendar\_db
export DB\_USER=calendar
export DB\_PASS=secret
```

Запуск севрера
``./build/calendar\_server``

Комнада для заупска тестов
``ctest --output-on-failure``

Запуск приложения
``./desktop\_app``


